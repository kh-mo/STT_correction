문법적 오류 수정 네트워크 학습을 위한 데이터 augmentation 방법론

GEC는 Grammatical Error Correction의 줄임말로 문법 오류 수정을 뜻한다.
딥러닝에서 seq2seq 패러다임이 높은 성능을 보이면서 gec를 딥러닝으로 풀고자하는 시도가 있었다.
기존에 많은 방법론들이 문제를 풀어낼 수 있는 가능성을 보여왔고 최근 microsoft research 팀에서 딥러닝을 이용해 human-level에 이른 연구 결과를 발표했다.
이들이 제안한 방법론은 FB Learning과 FB Inference라 한다.

seq2seq를 이용해서 gec를 풀 때 문제가 되는 부분은 다음과 같다.
1. training data 갯수에 한계가 있다.
2. 단 한번의 inference론 많은 문법적 오류를 정확히 수정하지 못한다.

FB Learning은 발생할 수 있는 문장 오류와 정확한 문장을 pair로 하여 추가적인 데이터를 생성해내는 방법이다.
이로 인해 generalization에 좀 더 근접할 수 있게 된다.
FB Inference는 fluency라고 칭해지는 문장의 유창성 점수가 정확한 문장보다 낮을경우 여러번 inference를 시행하는 방법론이다.

두 방법론을 적용하여 해당 논문은 이제 gec 분야가 human level에 도달했음을 이야기한다.

FB Learning 방법론은 크게 세가지로 구분해 적용할 수 있다.
첫번째는 back-boost 방법론이다.
문장 생성 모델을 만들어 학습 가능한 train pair를 늘리고 이를 이용하여 학습하는 방법론을 말한다.